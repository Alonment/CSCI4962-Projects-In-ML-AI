{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCI4692_HW2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1J6g1Is9CytHn-pdbxkGWRR2UVScr0PjO",
      "authorship_tag": "ABX9TyNkRC3lKXsjYPr+v7I4WpoJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Alonment/CSCI4962-Projects-In-ML-AI/blob/main/CSCI4692_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbiI2girsEv0"
      },
      "source": [
        "# Homework 2: Ensemble Learning\n",
        "\n",
        "**Task 1(30 points)**: Implement a Decision Tree Clasifier for your classification problem. You may use a built-in package to implement your classifier. Try modifying one or more of the input parameters and describe what changes you notice in your results. Clearly describe how these factors are affecting your output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNcBKfXAsmvy"
      },
      "source": [
        "Let's start off by loading and cleaning our data as we did from the previous homework."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULFURgIWdETD"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Load our data\n",
        "data = pd.read_csv('drive/MyDrive/high_diamond_ranked_10min.csv')\n",
        "\n",
        "#Clean our data\n",
        "cleaned_data = data.copy()\n",
        "cleaned_data = cleaned_data[cleaned_data[\"blueWardsPlaced\"] < 75]\n",
        "cleaned_data = cleaned_data[cleaned_data[\"redWardsPlaced\"] < 75]\n",
        "cleaned_data = cleaned_data.drop([\"blueTotalGold\", \"redTotalGold\", \"redGoldDiff\", \"blueTotalExperience\",\n",
        "                   \"redTotalExperience\", \"redExperienceDiff\", \"blueAvgLevel\", \"redAvgLevel\",\n",
        "                   \"gameId\", \"blueFirstBlood\", \"redFirstBlood\"], axis=1)\n",
        "\n",
        "#Separate data into training and test sets\n",
        "Y = cleaned_data.pop(\"blueWins\").values\n",
        "X = cleaned_data.to_numpy()\n",
        "\n",
        "#Holdout method replaced with k-fold cross val\n",
        "#X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, train_size = 0.9, test_size = 0.1, random_state = 0)\n",
        "\n",
        "#Initiliaze our decision-classification tree object\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "#Train our decision tree\n",
        "model = model.fit(X, Y)\n"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh1b7a6Qs1DT"
      },
      "source": [
        "Here, we've utilized sklearn's implementation of a Decision Tree Classifier along with all of its default parameter values. (i.e. max_depth = \"until leaves are singleton or all leaves contain less than min_sample_split_samples\", min_samples_split = 2, max_features = n_features, min_impurity_split = 0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ze3KKFCje2N8",
        "outputId": "ee905301-a330-44de-da1e-cb76d72c26e6"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "\n",
        "def cross_val_accuracy(model, X, Y):\n",
        "  \"\"\"\n",
        "  Prints out the accuracy of a model on a given X, Y set \n",
        "  by utilizing Repeated KFold Cross Validation\n",
        "  \"\"\"\n",
        "  \n",
        "  cv = RepeatedKFold(n_splits = 10, n_repeats=3, random_state = 0)\n",
        "  cv_scores = cross_val_score(model, X, Y, scoring = 'accuracy', cv=cv, n_jobs=-1, error_score = 'raise')\n",
        "  print('Accuracy: %.3f (%.3f)' % (np.mean(cv_scores), np.std(cv_scores)))\n",
        "\n",
        "print(\"Default sklearn DecisionTreeClasifier\")\n",
        "cross_val_accuracy(model, X, Y)\n"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default sklearn DecisionTreeClasifier\n",
            "Accuracy: 0.633 (0.015)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNelkTrwuABP"
      },
      "source": [
        "With RepeatedKFold cross validation, we can see that the default classification tree has rather low accuracy. Now, it would probably be best to test what different input parameters would do to our model as well as its accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U-limGhzqdR",
        "outputId": "68add8d9-36b3-4182-de5a-9635b37fb66e"
      },
      "source": [
        "# Testing with different max_depths values\n",
        "\n",
        "model_low_max_depth = DecisionTreeClassifier(max_depth = 5).fit(X,Y)\n",
        "print(\"Model with low max_depth input\")\n",
        "cross_val_accuracy(model_low_max_depth, X, Y)\n",
        "\n",
        "model_high_max_depth = DecisionTreeClassifier(max_depth = 30).fit(X,Y)\n",
        "print(\"Model with high max_depth input\")\n",
        "cross_val_accuracy(model_high_max_depth, X, Y)\n",
        "\n",
        "model_super_high_max_depth = DecisionTreeClassifier(max_depth = 300).fit(X,Y)\n",
        "print(\"Model with super high max_depth input\")\n",
        "cross_val_accuracy(model_super_high_max_depth, X, Y)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model with low max_depth input\n",
            "Accuracy: 0.724 (0.013)\n",
            "Model with high max_depth input\n",
            "Accuracy: 0.632 (0.015)\n",
            "Model with super high max_depth input\n",
            "Accuracy: 0.635 (0.016)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlqbsD_Q4FK3"
      },
      "source": [
        "Low values of max_depth appear to produce higher model accuracy while larger values of max_depth tend to produce lower accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOh3Q0vG1sHf",
        "outputId": "217d8a8b-409a-48fe-8059-d4f4e2a2c63b"
      },
      "source": [
        "# Testing with different min_samples_split values\n",
        "\n",
        "model_low_min_samples_split = DecisionTreeClassifier(min_samples_split = 2).fit(X,Y)\n",
        "print(\"Model with low min_samples_split input\")\n",
        "cross_val_accuracy(model_low_min_samples_split, X, Y)\n",
        "\n",
        "model_high_min_samples_split = DecisionTreeClassifier(min_samples_split = 30).fit(X,Y)\n",
        "print(\"Model with high min_samples_split input\")\n",
        "cross_val_accuracy(model_high_min_samples_split, X, Y)\n",
        "\n",
        "model_super_high_min_samples_split = DecisionTreeClassifier(min_samples_split = 300).fit(X,Y)\n",
        "print(\"Model with super high min_samples_split input\")\n",
        "cross_val_accuracy(model_super_high_min_samples_split, X, Y)"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model with low min_samples_split input\n",
            "Accuracy: 0.632 (0.018)\n",
            "Model with high min_samples_split input\n",
            "Accuracy: 0.659 (0.015)\n",
            "Model with super high min_samples_split input\n",
            "Accuracy: 0.717 (0.015)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4_qm5B04b_6"
      },
      "source": [
        "Lower values of min_samples_split appear to produce lower model accuracy while large values of min_samples_split tend to produce higher accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b258d86-2qtH",
        "outputId": "340d55d3-5a04-4b0c-da3d-c5d4fb3609e3"
      },
      "source": [
        "# Testing with different max_features values\n",
        "\n",
        "model_low_max_features = DecisionTreeClassifier(max_features = 5).fit(X,Y)\n",
        "print(\"Model with low max_features input\")\n",
        "cross_val_accuracy(model_low_max_features, X, Y)\n",
        "\n",
        "model_high_max_features = DecisionTreeClassifier(max_features = 15).fit(X,Y)\n",
        "print(\"Model with high max_features input\")\n",
        "cross_val_accuracy(model_high_max_features, X, Y)\n",
        "\n",
        "model_super_high_max_features = DecisionTreeClassifier(max_features = len(X[0])).fit(X,Y)\n",
        "print(\"Model with super high max_features input\")\n",
        "cross_val_accuracy(model_super_high_max_features, X, Y)"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model with low max_features input\n",
            "Accuracy: 0.634 (0.017)\n",
            "Model with high max_features input\n",
            "Accuracy: 0.633 (0.014)\n",
            "Model with super high max_features input\n",
            "Accuracy: 0.631 (0.012)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCVotz4m4llJ"
      },
      "source": [
        "The input parameter max_features appears to have no real effect on the accuracy of our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4xFgjxK3Kf1",
        "outputId": "4bdc8989-1526-4b1e-ca8a-66c20765248a"
      },
      "source": [
        "# Testing with different min_impurity_split values\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning) # Ignore deprecation warning on min_impurity_split\n",
        "\n",
        "model_low_min_impurity_split = DecisionTreeClassifier(min_impurity_split = 0.0).fit(X,Y)\n",
        "print(\"Model with low min_impurity_split input\")\n",
        "cross_val_accuracy(model_low_min_impurity_split, X, Y)\n",
        "\n",
        "model_high_min_impurity_split = DecisionTreeClassifier(min_impurity_split = 0.4).fit(X,Y)\n",
        "print(\"Model with high min_impurity_split input\")\n",
        "cross_val_accuracy(model_high_min_impurity_split, X, Y)\n",
        "\n",
        "model_super_high_min_impurity_split = DecisionTreeClassifier(min_impurity_split = 0.9).fit(X,Y)\n",
        "print(\"Model with super high min_impurity_split input\")\n",
        "cross_val_accuracy(model_super_high_min_impurity_split, X, Y)"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model with low min_impurity_split input\n",
            "Accuracy: 0.633 (0.012)\n",
            "Model with high min_impurity_split input\n",
            "Accuracy: 0.716 (0.015)\n",
            "Model with super high min_impurity_split input\n",
            "Accuracy: 0.490 (0.008)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUCjoo1d4wRo"
      },
      "source": [
        "Low to medium values for min_impurity_split tend to produce more a more accurate model than that of larger min_impurity_split values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QIHSAUD65aA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27467589-5001-4884-8bac-cbed4d5c6422"
      },
      "source": [
        "# Testing different combinations based off the best values from the above tests\n",
        "\n",
        "modelOne = DecisionTreeClassifier(max_depth = 5, min_samples_split = 300, min_impurity_split = 0.4).fit(X,Y)\n",
        "print(\"Model with supposed best input parameters\")\n",
        "cross_val_accuracy(modelOne, X, Y)\n",
        "\n",
        "modelTwo = DecisionTreeClassifier(max_depth = 500, min_samples_split = 75, min_impurity_split = 0.4).fit(X,Y)\n",
        "print(\"Model that is less shallow but maintains same impurity_split\")\n",
        "cross_val_accuracy(modelTwo, X, Y)\n",
        "\n",
        "modelThree = DecisionTreeClassifier(max_depth = 500, min_samples_split = 20, min_impurity_split = 0.1).fit(X,Y)\n",
        "print(\"Model with more realistic inputs to combat overfitting at the cost of accuracy\")\n",
        "cross_val_accuracy(modelThree, X, Y)\n",
        "\n",
        "\n",
        "print(\"\\nIdeal model: modelTwo\")\n",
        "cross_val_accuracy(modelTwo, X, Y)"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model with supposed best input parameters\n",
            "Accuracy: 0.729 (0.015)\n",
            "Model that is less shallow but maintains same impurity_split\n",
            "Accuracy: 0.717 (0.016)\n",
            "Model with more realistic inputs to combat overfitting at the cost of accuracy\n",
            "Accuracy: 0.651 (0.018)\n",
            "\n",
            "Ideal model: modelTwo\n",
            "Accuracy: 0.717 (0.016)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dphuEQGe76wW"
      },
      "source": [
        "As we can see from the various models tested with a wide range of differing input parameter values, max_features tended to not have an effect at all on the accuracy of our model while the three other features, max_depth, min_samples_split, and min_impurity had their own respective effects and tradeoffs on the model's accuracy. Upon analyzing each parameter individually as well as collectively, I suppose that the best model would probably have to be **modelTwo** since it provides a relatively high accuracy whilst still having realistic parameters that prevents the tree from being too shallow and therefore capable of generalizing well outside of $D_N$. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DcMtJQaM-vwQ"
      },
      "source": [
        "**Task 2(30 points)**: From the Bagging and Boosting methods pick any one algorithm from each category. Implement both the algorithms using the same data. Use k-fold cross validation to find the effectiveness of both the models. Comment on the difference/similarity of the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWpL8ivdAiPe",
        "outputId": "310bbd89-35e3-45ad-9232-fe6c7929ac4a"
      },
      "source": [
        "#Adaptive Boosting with DecisionTreeClassifiers\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "\n",
        "# We let modelOne be our estimator since boost methods work best with shallow trees\n",
        "model_with_adaboost = AdaBoostClassifier(modelOne, random_state = 0, algorithm='SAMME')\n",
        "model_with_adaboost.fit(X, Y)\n",
        "print(\"Adaboost\")\n",
        "cross_val_accuracy(model_with_adaboost, X, Y)"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adaboost\n",
            "Accuracy: 0.724 (0.012)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYujVKdkROnc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "701e75a8-ef72-4ade-f018-ff1e0ced1f58"
      },
      "source": [
        "# Random Forest\n",
        "# Initialize with same input parameters as modelTwo\n",
        "model_with_RF = RandomForestClassifier(max_depth = 500, min_samples_split = 75, min_impurity_split = 0.4)\n",
        "model_with_RF.fit(X,Y)\n",
        "print(\"Random Forest\")\n",
        "cross_val_accuracy(model_with_RF, X, Y)"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest\n",
            "Accuracy: 0.729 (0.014)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI9GQn5YKo88"
      },
      "source": [
        "The algorithms from Bagging and Boosting that I decided to implement were Random Forest and Adaboost respectively. In regards to their results from KFold cross validation, the Random Forest implementation succeeded in increasing accuracy and significantly decreasing modelTwo's variance(lower std) while the Adaboost implementation appears to also have lowered variance significantly while actually having a lower accuracy than modelOne.\n",
        "\n",
        "**Analysis of Adaboost**:\n",
        "\n",
        "Boost ensemble algorithms tend to be comprised of weak learners where bias and variance are ideally reduced in attempt to convert these weak learners into a final, strong model. Since the adaboost model, which was comprised of modelOne(an extremely shallow tree, i.e. max_depth = 5 and min_samples_split = 300), produced a marginally lower accuracy with a significantly lower variance than that of modelOne itself, the model itself appears to have been a success, seeing how bias must have been near its optimal trade-off value already since the accuracy has barely changed while the variance has greatly decreased. \n",
        "\n",
        "**Analysis of Random Forest**:\n",
        "\n",
        "Bagging ensemble algorithms tend to also be composed of weak learners designed to provide an optimal final prediction based on the average prediction across all the learners. Since the random forest model, which was comprised of modelTwo ( a somewhat shallow tree, but not to the same degree as modelOne ), produced a slightly significant increase in accuracy along with a significant decrease in variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlFskAu1R19j"
      },
      "source": [
        "**Task 3(40 points)**: Compare the effectiveness of the three models implemented above. Clearly describe the metric you are using for comparison. Describe (with examples) why is this metric/metrics suited for the problem at hand? How would a choice of a different metric impact your results? Can you demonstrate that?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne5I6z522SfE",
        "outputId": "915d3d0f-40ff-419c-d837-2a7cce37aae9"
      },
      "source": [
        "# Import metric score analysis functions\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)\n",
        "\n",
        "y_pred = modelTwo.fit(X_train, y_train).predict(X_test)\n",
        "cm_vanilla = confusion_matrix(y_test, y_pred)\n",
        "print(\"modelTwo (Single Descision Tree Classifier):\\n\", cm_vanilla)\n",
        "print(f\"Accuracy: {accuracy_score(y_pred, y_test)}\")\n",
        "print(f\"Precision: {precision_score(y_pred, y_test)}\\n\")\n",
        "\n",
        "y_pred = model_with_adaboost.fit(X_train, y_train).predict(X_test)\n",
        "cm_adaboost = confusion_matrix(y_test, y_pred)\n",
        "print(\"Adaptive Boost Model:\\n\", cm_adaboost)\n",
        "print(f\"Accuracy: {accuracy_score(y_pred, y_test)}\")\n",
        "print(f\"Precision: {precision_score(y_pred, y_test)}\\n\")\n",
        "\n",
        "y_pred = model_with_RF.fit(X_train, y_train).predict(X_test)\n",
        "cm_rf = confusion_matrix(y_test, y_pred)\n",
        "print(\"Random Forest Model:\\n\", cm_rf)\n",
        "print(f\"Accuracy: {accuracy_score(y_pred, y_test)}\")\n",
        "print(f\"Precision: {precision_score(y_pred, y_test)}\")"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modelTwo (Single Descision Tree Classifier):\n",
            " [[753 419]\n",
            " [245 916]]\n",
            "Accuracy: 0.715387912558937\n",
            "Precision: 0.788975021533161\n",
            "\n",
            "Adaptive Boost Model:\n",
            " [[868 304]\n",
            " [331 830]]\n",
            "Accuracy: 0.727818259751393\n",
            "Precision: 0.7149009474590869\n",
            "\n",
            "Random Forest Model:\n",
            " [[852 320]\n",
            " [308 853]]\n",
            "Accuracy: 0.7308186883840548\n",
            "Precision: 0.7347114556416882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m62dHu0p5Jhh"
      },
      "source": [
        "The metric that I will be using to compare the effectiveness of the three models is that of accuracy since from our previous EDA, we know that the classes in our data are nearly balanced (i.e. blueWins ≈ 0.49...). This makes sense because one of the qualities of our data set is the fact that all of the players are of the same skill level, with that skill level itself being high. This reduces the amount of randomess that may occur during a game and allows a more deterministic approach to analyzing the game and the effect various features may have on the outcome (i.e. lower player skill disparity + game is played the way it was meant to be played). In regards to the three models, the adaboost and random forest models clearly had a better accuracy than that of our vanilla modelTwo (single Decision Tree), with the random forest model ultimately outperforming the adaboost model despite their scores being very, very close.\n",
        "\n",
        "Choosing another metric to measure our models' effectiveness could easily change our results and conclusions. Let us demonstrate this by choosing to measure our models based on their precision. When comparing the three models based on their precision, the single decision tree, modelTwo, outperformed the other models significantly, with adaboost coming in last and random forest coming in second. Thus, in this world where precision is our metric, we would consider modelTwo to be the superior model in terms of effectiveness, which is a stark difference when compared to utilizing accuracy as a metric. "
      ]
    }
  ]
}